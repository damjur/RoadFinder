{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jurgad\\Downloads\\WinPython-64bit-3.6.3.0Qt5\\python-3.6.3.amd64\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, concatenate\n",
    "from keras.layers import Conv2D, MaxPooling2D,UpSampling2D,Lambda, ZeroPadding2D\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.regularizers import l1_l2\n",
    "\n",
    "class MyException(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOWMANY = None\n",
    "MAXLINKS = 1109\n",
    "DEBUG = True\n",
    "TMP_DIR = 'tmp'\n",
    "FORCE_RELOAD = False#True\n",
    "LOAD = True\n",
    "PREPROCESS = True#False\n",
    "batch_size = 128   # ile obrazków przetwarzamy na raz (aktualizacja wag sieci następuje raz na całą grupę obrazków)\n",
    "epochs = 12         # ile epok będziemy uczyli\n",
    "SIZE = (750,750)\n",
    "SIDE = 75\n",
    "IMPOSITION = 5\n",
    "HOWMANYPERIMAGE = int(SIZE[0]*SIZE[1]/SIDE/SIDE)\n",
    "IMAGESPERFILE = 100\n",
    "assert int(SIZE[0]*SIZE[1]/SIDE/SIDE)==HOWMANYPERIMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImage(url):\n",
    "    raw = urllib.request.urlopen(url).read()\n",
    "    npraw= np.array(bytearray(raw),dtype=np.uint8)\n",
    "    return cv2.imdecode(npraw,-1)#-1 -> as is (with the alpha channel)\n",
    "\n",
    "def getImageName(url):\n",
    "    return url.split('/').pop().split('.').pop(0)\n",
    "\n",
    "def pickleBigDataset(prefix,dataset,size):\n",
    "    j = int(np.ceil(len(dataset)/size))\n",
    "    for i in range(1,j+1):\n",
    "        np.save(os.path.join(TMP_DIR, prefix+str(i)),np.array(dataset[size*(i-1):size*i]))\n",
    "\n",
    "def unpickleBigDataset(prefix):\n",
    "    onlyfiles = [f for f in os.listdir(TMP_DIR) if os.path.isfile(os.path.join(TMP_DIR, f))\n",
    "                 and f.startswith(prefix)]\n",
    "    dataset = []\n",
    "    if len(onlyfiles)>0:\n",
    "        dataset = np.load(os.path.join(TMP_DIR, onlyfiles[0]))\n",
    "        for f in onlyfiles[1:]:\n",
    "            dataset=np.append(dataset,np.load(os.path.join(TMP_DIR, f)),axis=0)\n",
    "    return dataset\n",
    "#     return np.load(os.path.join(TMP_DIR, \"{}.npy\".format(prefix)))\n",
    "    \n",
    "            \n",
    "def loadImagesFromSite(url,prefix):\n",
    "    onlyfiles = [f for f in os.listdir(TMP_DIR) if os.path.isfile(os.path.join(TMP_DIR, f)) and f.startswith(prefix)]\n",
    "    if len(onlyfiles)==0 or FORCE_RELOAD:\n",
    "        imgs = []\n",
    "        I = None\n",
    "        \n",
    "    else:\n",
    "        imgs = [img for img in unpickleBigDataset(prefix)[:HOWMANY]]\n",
    "        I = len(imgs)\n",
    "    print(\"Cached images {}.\".format(I if I is not None else 0))\n",
    "    \n",
    "    if (HOWMANY is not None and len(imgs)<HOWMANY and len(imgs)<MAXLINKS) or (len(imgs)<MAXLINKS and HOWMANY is None):\n",
    "        print(\"Loading images from {}\".format(url))\n",
    "        print(\"Proceeding from {} image.\".format(I if I is not None else 0))\n",
    "\n",
    "        s = IMAGESPERFILE\n",
    "\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            html = BeautifulSoup(response.read(),\"lxml\")\n",
    "            i = I if I is not None else 0\n",
    "            links = html.find_all('a')[I:HOWMANY]\n",
    "            for link in tqdm_notebook(links):\n",
    "                img = loadImage(link.get('href'))  \n",
    "                img = cv2.resize(img,SIZE)\n",
    "                imgs += [cv2.resize(img,SIZE)]\n",
    "                if i%s==0:\n",
    "                    pickleBigDataset(prefix,imgs,s)\n",
    "                i+=1\n",
    "        pickleBigDataset(prefix,imgs,s)\n",
    "    \n",
    "        \n",
    "    return np.array(imgs)  \n",
    "\n",
    "def saveDataset(X,Y,prefix=\"\"):\n",
    "    with open('pickledDatasetX'+prefix,'wb') as f:\n",
    "        pickle.dump(X,f)\n",
    "    with open('pickledDatasetY'+prefix,'wb') as f:\n",
    "        pickle.dump(Y,f)\n",
    "        \n",
    "def loadDataset(prefix=\"\"):\n",
    "    try:\n",
    "        X = unpickleBigDataset('x')\n",
    "        Y = unpickleBigDataset('y')\n",
    "        if len(X) == len(Y) and len(X) == HOWMANY:\n",
    "            return X,Y\n",
    "        else:\n",
    "            print(\"Failed loading dataset from file system\")\n",
    "            return None,None\n",
    "    except:\n",
    "        print(\"Failed loading dataset from file system\")\n",
    "        return None,None\n",
    "    \n",
    "def display(X,Y,howmany=None):\n",
    "    if howmany is None:\n",
    "        howmany = X.shape[0]\n",
    "        \n",
    "    for i in range(howmany):\n",
    "        print(X[i].max(),X[i].min())\n",
    "        plt.figure()\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(X[i])\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(Y[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_patches(image,size,side,imposition):\n",
    "#     patches = []\n",
    "    \n",
    "    \n",
    "#     for i in range(int(size[0]/side)):\n",
    "#         for j in range(int(size[1]/side)):\n",
    "#             patches += [image[i*side:(i+1)*side,j*side:(j+1)*side]]\n",
    "#     return patches\n",
    "\n",
    "def get_patches(image,size,side,imposition):\n",
    "    patches = []\n",
    "    \n",
    "    if len(image.shape)==3:\n",
    "        img = np.zeros((image.shape[0]+imposition,image.shape[1]+imposition,3))\n",
    "        for i in range(3):\n",
    "            img[...,i] = np.pad(image[...,i],((imposition,0),(imposition,0)),'reflect')\n",
    "        image = img\n",
    "    else:\n",
    "        image = np.pad(image,((imposition,0),(imposition,0)),'reflect')\n",
    "\n",
    "    for i in range(int(size[0]/side)):\n",
    "        for j in range(int(size[1]/side)):\n",
    "            imp1=np.max([i*side-imposition,0])\n",
    "            imp2=(i+1)*side+imposition if imp1!=0 else (i+1)*side+imposition*2\n",
    "            imp3=np.max([j*side-imposition,0])\n",
    "            imp4=(j+1)*side+imposition if imp3!=0 else (j+1)*side+imposition*2\n",
    "            patches += [image[imp1:imp2,imp3:imp4]]\n",
    "    return patches\n",
    "\n",
    "def preprocessorX(image):\n",
    "    size,side,imposition = SIZE,SIDE,IMPOSITION\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    image = image.astype(np.float32)\n",
    "\n",
    "    if image.max() > 1:\n",
    "        image /= 255\n",
    "\n",
    "    for i in range(3):\n",
    "        image[...,i] -= image[...,i].mean()\n",
    "        image[...,i] /= image[...,i].std()\n",
    "\n",
    "    #remove outliers\n",
    "    image[image<-3] = -3\n",
    "    image[image>3] = 3\n",
    "\n",
    "    #between -1,1\n",
    "    for i in range(3):\n",
    "        image[...,i] /= np.max(np.abs([image[...,i].min(),image[...,i].max()]))\n",
    "\n",
    "    return get_patches(image,size,side,imposition)\n",
    "    \n",
    "def preprocessorY(image):\n",
    "    size,side,imposition = SIZE,SIDE,IMPOSITION\n",
    "\n",
    "    image = image.astype(np.float32)\n",
    "    if image.max() > 1:\n",
    "        image /= 255\n",
    "    for i in range(3):\n",
    "        image[...,i] = (image[...,i] - image[...,i].min())/(image[...,i].max() - image[...,i].min())\n",
    "    return get_patches(image,size,side,imposition)\n",
    "    \n",
    "def getRoadStats(arr,mask):\n",
    "    b = mask.astype(np.bool)\n",
    "    x = arr[b]\n",
    "    if len(x) != 0:\n",
    "        return [x.max(0),x.min(0),x.mean(0),x.std(0),np.median(x,axis=0)]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def preprocessXY(X,Y):\n",
    "    \n",
    "    r = []\n",
    "    for i in range(len(X)):\n",
    "        s = getRoadStats(X[i],Y[i])\n",
    "        if s is not None:\n",
    "            r += [s]\n",
    "            \n",
    "    return np.array(r).mean(0)\n",
    "    \n",
    "\n",
    "def preprocess(images,preprocessor,prefix):\n",
    "    onlyfiles = [f for f in os.listdir(TMP_DIR) if os.path.isfile(os.path.join(TMP_DIR, f)) and f.startswith(prefix)]\n",
    "    if len(onlyfiles)==0:\n",
    "        I = None\n",
    "        result = []\n",
    "    else:\n",
    "        result = unpickleBigDataset(prefix)[:HOWMANY*HOWMANYPERIMAGE]\n",
    "        I = len(result)\n",
    "    print(\"Cached images {}.\".format(len(result)))\n",
    "    \n",
    "    s = IMAGESPERFILE * HOWMANYPERIMAGE\n",
    "    if len(result)<HOWMANY*HOWMANYPERIMAGE:\n",
    "        print(\"Preprocessing images.\")\n",
    "        print(\"Proceeding from {} image.\".format(I if I is not None else 0))\n",
    "        i = I if I is not None else 0\n",
    "        ignoring = []\n",
    "        for image in tqdm_notebook(images[I:]):\n",
    "            r = preprocessor(image)\n",
    "            result += r\n",
    "            if i%s==0:\n",
    "                pickleBigDataset(prefix,result,s)\n",
    "        pickleBigDataset(prefix,result,s)\n",
    "    images = None\n",
    "        \n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doSomeDeepLearning(X=None,Y=None,side=85):\n",
    "    num_classes = 2    # ile klas będziemy rozpoznawali\n",
    "\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = side,side   # takie wymiary mają obrazki w bazie MNIST\n",
    "\n",
    "    # the data, shuffled and split between train and test sets\n",
    "    try:\n",
    "        x_train = unpickleBigDataset('xain')\n",
    "        y_train = unpickleBigDataset('yain')\n",
    "        x_test = unpickleBigDataset('xest')\n",
    "        y_test = unpickleBigDataset('yest')\n",
    "        if len(x_train)==0 or len(y_train)==0 or len(x_test)==0 or len(y_test)==0:\n",
    "            raise Exception\n",
    "        if len(x_train) + len(x_test)!=HOWMANY:\n",
    "            raise MyException\n",
    "    except:\n",
    "        if X is None or Y is None:\n",
    "            raise MyException\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "            x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "            y_train = y_train.reshape(y_train.shape[0], 1, img_rows, img_cols)\n",
    "            y_test = y_test.reshape(y_test.shape[0], 1, img_rows, img_cols)\n",
    "            input_shape = (1, img_rows, img_cols)\n",
    "        else:\n",
    "            x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "            x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "            y_train = y_train.reshape(y_train.shape[0], img_rows, img_cols, 1)\n",
    "            y_test = y_test.reshape(y_test.shape[0], img_rows, img_cols, 1)\n",
    "            input_shape = (img_rows, img_cols, 1)\n",
    "        s = IMAGESPERFILE * HOWMANYPERIMAGE\n",
    "        pickleBigDataset('xain',x_train,s)\n",
    "        pickleBigDataset('yain',y_train,s)\n",
    "        pickleBigDataset('xest',x_test,s)\n",
    "        pickleBigDataset('yest',y_test,s)\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    \n",
    "    curr_epoch = -1\n",
    "    onlyfiles = [f for f in os.listdir('.') if os.path.isfile(os.path.join('.', f)) and f.startswith('moj_ulubiony_model') and f.endswith('.h5')]\n",
    "    if len(onlyfiles) == 0:\n",
    "        print(\"No saved model. Preparing model.\")\n",
    "        imput = Input(shape=(side,side,3))\n",
    "        conv1 = Conv2D(32, \n",
    "                       kernel_size=(3,3),\n",
    "                       padding=\"same\", \n",
    "                       activation='relu',\n",
    "                       kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=l1_l2(0.01),\n",
    "                       bias_regularizer=l1_l2(0.01),\n",
    "                       activity_regularizer=l1_l2(0.01)\n",
    "                      )(imput)\n",
    "        conv1 = Conv2D(32, kernel_size=(3,3), \n",
    "                       kernel_size=(3,3),\n",
    "                       padding=\"same\", \n",
    "                       activation='relu',\n",
    "                       kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=l1_l2(0.01),\n",
    "                       bias_regularizer=l1_l2(0.01),\n",
    "                       activity_regularizer=l1_l2(0.01)\n",
    "                      )(conv1)\n",
    "        conv1 = Conv2D(32, \n",
    "                       kernel_size=(3,3),\n",
    "                       padding=\"same\", \n",
    "                       activation='relu',\n",
    "                       kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=l1_l2(0.01),\n",
    "                       bias_regularizer=l1_l2(0.01),\n",
    "                       activity_regularizer=l1_l2(0.01)\n",
    "                      )(conv1)\n",
    "        dropout1 = Dropout(0.2)(conv1)\n",
    "        maxpool1 = MaxPooling2D(pool_size=(2, 2))(dropout1)\n",
    "        conv2 = Conv2D(64, \n",
    "                       kernel_size=(3,3),\n",
    "                       padding=\"same\", \n",
    "                       activation='relu',\n",
    "                       kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=l1_l2(0.01),\n",
    "                       bias_regularizer=l1_l2(0.01),\n",
    "                       activity_regularizer=l1_l2(0.01)\n",
    "                      )(maxpool1)\n",
    "        conv2 = Conv2D(64, \n",
    "                       kernel_size=(3,3),\n",
    "                       padding=\"same\", \n",
    "                       activation='relu',\n",
    "                       kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=l1_l2(0.01),\n",
    "                       bias_regularizer=l1_l2(0.01),\n",
    "                       activity_regularizer=l1_l2(0.01)\n",
    "                      )(conv2)\n",
    "        conv2 = Conv2D(64, \n",
    "                       kernel_size=(3,3),\n",
    "                       padding=\"same\", \n",
    "                       activation='relu',\n",
    "                       kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=l1_l2(0.01),\n",
    "                       bias_regularizer=l1_l2(0.01),\n",
    "                       activity_regularizer=l1_l2(0.01)\n",
    "                      )(conv2)\n",
    "        dropout2 = Dropout(0.25)(conv2)\n",
    "        maxpool2 = MaxPooling2D(pool_size=(2, 2))(dropout2)\n",
    "        conv3 = Conv2D(128, \n",
    "                       kernel_size=(3,3),\n",
    "                       padding=\"same\", \n",
    "                       activation='relu',\n",
    "                       kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=l1_l2(0.01),\n",
    "                       bias_regularizer=l1_l2(0.01),\n",
    "                       activity_regularizer=l1_l2(0.01)\n",
    "                      )(maxpool2)\n",
    "        conv3 = Conv2D(128, \n",
    "                       kernel_size=(3,3),\n",
    "                       padding=\"same\", \n",
    "                       activation='relu',\n",
    "                       kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=l1_l2(0.01),\n",
    "                       bias_regularizer=l1_l2(0.01),\n",
    "                       activity_regularizer=l1_l2(0.01)\n",
    "                      )(conv3)\n",
    "        conv3 = Conv2D(128, \n",
    "                       kernel_size=(3,3),\n",
    "                       padding=\"same\", \n",
    "                       activation='relu',\n",
    "                       kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=l1_l2(0.01),\n",
    "                       bias_regularizer=l1_l2(0.01),\n",
    "                       activity_regularizer=l1_l2(0.01)\n",
    "                      )(conv3)\n",
    "        dropout3 = Dropout(0.25)(conv3)\n",
    "        upsample1 = UpSampling2D(size=(2,2))(dropout3)\n",
    "        \n",
    "        concat1 = concatenate([upsample1,conv2,])#lambda1])\n",
    "        conv4 = Conv2D(64, \n",
    "                       kernel_size=(3,3),\n",
    "                       padding=\"same\", \n",
    "                       activation='relu',\n",
    "                       kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=l1_l2(0.01),\n",
    "                       bias_regularizer=l1_l2(0.01),\n",
    "                       activity_regularizer=l1_l2(0.01)\n",
    "                      )(concat1)\n",
    "        conv4 = Conv2D(64, \n",
    "                       kernel_size=(3,3),\n",
    "                       padding=\"same\", \n",
    "                       activation='relu',\n",
    "                       kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=l1_l2(0.01),\n",
    "                       bias_regularizer=l1_l2(0.01),\n",
    "                       activity_regularizer=l1_l2(0.01)\n",
    "                      )(conv4)\n",
    "        conv4 = Conv2D(64, \n",
    "                       kernel_size=(3,3),\n",
    "                       padding=\"same\", \n",
    "                       activation='relu',\n",
    "                       kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=l1_l2(0.01),\n",
    "                       bias_regularizer=l1_l2(0.01),\n",
    "                       activity_regularizer=l1_l2(0.01)\n",
    "                      )(conv4)\n",
    "        dropout4 = Dropout(0.25)(conv4)\n",
    "        upsample2 = UpSampling2D(size=(2,2))(dropout4)\n",
    "        zpad1 = ZeroPadding2D(((1,0),(1,0)))(upsample2)\n",
    "        concat2 = concatenate([zpad1,conv1])\n",
    "        conv5 = Conv2D(32, \n",
    "                       kernel_size=(3,3),\n",
    "                       padding=\"same\", \n",
    "                       activation='relu',\n",
    "                       kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=l1_l2(0.01),\n",
    "                       bias_regularizer=l1_l2(0.01),\n",
    "                       activity_regularizer=l1_l2(0.01)\n",
    "                      )(concat2)\n",
    "        conv5 = Conv2D(32, \n",
    "                       kernel_size=(3,3),\n",
    "                       padding=\"same\", \n",
    "                       activation='relu',\n",
    "                       kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=l1_l2(0.01),\n",
    "                       bias_regularizer=l1_l2(0.01),\n",
    "                       activity_regularizer=l1_l2(0.01)\n",
    "                      )(conv5)\n",
    "        conv5 = Conv2D(1, \n",
    "                       kernel_size=(3,3),\n",
    "                       padding=\"same\", \n",
    "                       activation='relu',\n",
    "                       kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=l1_l2(0.01),\n",
    "                       bias_regularizer=l1_l2(0.01),\n",
    "                       activity_regularizer=l1_l2(0.01)\n",
    "                      )(conv5)\n",
    "        model = Model(inputs=imput, outputs=conv5)\n",
    "\n",
    "        model.compile(loss=keras.losses.mean_squared_error,\n",
    "                  optimizer=keras.optimizers.Adam(),       \n",
    "                  metrics=['accuracy']) \n",
    "    elif len(onlyfiles) == 1:\n",
    "        print(\"Saved model:\\\"{}\\\"\".format(onlyfiles[0]))\n",
    "        model = keras.models.load_model(onlyfiles[0])\n",
    "    else:\n",
    "        onlyfiles = map(lambda y:filter(lambda x:x is not None and x.startswith('epoch'),y.split('.')[0].split('_')),onlyfiles)\n",
    "        curr_epoch = max(list(map(lambda x:int(x[4:]),onlyfiles)))\n",
    "        model = keras.models.load_model(\"moj_ulubiony_model_epoch{}.h5\".format(curr_epoch))\n",
    "        print(\"Saved model:\\\"moj_ulubiony_model_epoch{}.h5\\\"\".format(curr_epoch))\n",
    "    curr_epoch += 1\n",
    "    print(\"Current epoch:{}\".format(curr_epoch))\n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "    for i in range(curr_epoch,epochs):\n",
    "        model.fit(x_train, y_train,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=1,\n",
    "                      verbose=1,\n",
    "                      validation_data=(x_test, y_test))\n",
    "        model.save(\"moj_ulubiony_model_epoch{}.h5\".format(i))\n",
    "    \n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed loading dataset from file system\n",
      "Loading images (X)\n",
      "Cached images 0.\n",
      "Loading images from https://www.cs.toronto.edu/~vmnih/data/mass_roads/train/sat/index.html\n",
      "Proceeding from 0 image.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f173641cf4f741138d48a85aaece3918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1109), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jurgad\\Downloads\\WinPython-64bit-3.6.3.0Qt5\\python-3.6.3.amd64\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\jurgad\\Downloads\\WinPython-64bit-3.6.3.0Qt5\\python-3.6.3.amd64\\lib\\site-packages\\tqdm\\_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"C:\\Users\\jurgad\\Downloads\\WinPython-64bit-3.6.3.0Qt5\\python-3.6.3.amd64\\lib\\_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    try:\n",
    "        doSomeDeepLearning()\n",
    "    except MyException as e:\n",
    "        urlX = \"https://www.cs.toronto.edu/~vmnih/data/mass_roads/train/sat/index.html\"\n",
    "        urlY = \"https://www.cs.toronto.edu/~vmnih/data/mass_roads/train/map/index.html\"\n",
    "\n",
    "        X,Y = loadDataset()\n",
    "        if X is None and Y is None or DEBUG:\n",
    "            if LOAD:\n",
    "                print(\"Loading images (X)\")\n",
    "                X = loadImagesFromSite(urlX,'f')\n",
    "            if PREPROCESS:\n",
    "                print(\"Preprocessing images (X)\")\n",
    "                X = preprocess(X,preprocessorX,'x')\n",
    "            if LOAD:\n",
    "                print(\"Loading images (Y)\")\n",
    "                Y = loadImagesFromSite(urlY,'z')\n",
    "            if PREPROCESS:\n",
    "                print(\"Preprocessing images (Y)\")\n",
    "                Y = preprocess(Y,preprocessorY,'y')\n",
    "\n",
    "                r = preprocessXY(X,Y)\n",
    "                print(\"\\n\\t| {}\\t\\t\\t| {}\\t\\t| {}\".format('Hue', 'Saturation', 'Value'))\n",
    "                l = ['max','min','avg','std','median']\n",
    "                for i,(c1, c2, c3) in enumerate(r):  \n",
    "                    print(\"{}\\t| {}\\t| {}\\t| {}\".format(l[i],c1, c2, c3))\n",
    "\n",
    "        doSomeDeepLearning(X,Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
