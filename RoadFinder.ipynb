{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, concatenate\n",
    "from keras.layers import Conv2D, MaxPooling2D,UpSampling2D,Lambda, ZeroPadding2D\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class MyException(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOWMANY = 50\n",
    "MAXLINKS = 1109\n",
    "DEBUG = True\n",
    "TMP_DIR = 'tmp'\n",
    "FORCE_RELOAD = False#True\n",
    "LOAD = True\n",
    "PREPROCESS = True#False\n",
    "batch_size = 128   # ile obrazków przetwarzamy na raz (aktualizacja wag sieci następuje raz na całą grupę obrazków)\n",
    "epochs = 12         # ile epok będziemy uczyli\n",
    "SIZE = (750,750)\n",
    "SIDE = 75\n",
    "IMPOSITION = 5\n",
    "HOWMANYPERIMAGE = int(SIZE[0]*SIZE[1]/SIDE/SIDE)\n",
    "IMAGESPERFILE = 100\n",
    "assert int(SIZE[0]*SIZE[1]/SIDE/SIDE)==HOWMANYPERIMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImage(url):\n",
    "    raw = urllib.request.urlopen(url).read()\n",
    "    npraw= np.array(bytearray(raw),dtype=np.uint8)\n",
    "    return cv2.imdecode(npraw,-1)#-1 -> as is (with the alpha channel)\n",
    "\n",
    "def getImageName(url):\n",
    "    return url.split('/').pop().split('.').pop(0)\n",
    "\n",
    "def pickleBigDataset(prefix,dataset,size):\n",
    "    j = int(np.ceil(len(dataset)/size))\n",
    "    for i in range(1,j+1):\n",
    "        np.save(os.path.join(TMP_DIR, prefix+str(j)),np.array(dataset[size*(i-1):size*i]))\n",
    "\n",
    "def unpickleBigDataset(prefix):\n",
    "    onlyfiles = [f for f in os.listdir(TMP_DIR) if os.path.isfile(os.path.join(TMP_DIR, f))\n",
    "                 and f.startswith(prefix)]\n",
    "    dataset = []\n",
    "    if len(onlyfiles)>0:\n",
    "        dataset = np.load(os.path.join(TMP_DIR, onlyfiles[0]))\n",
    "        for f in onlyfiles[1:]:\n",
    "            dataset=np.append(dataset,np.load(os.path.join(TMP_DIR, f)),axis=0)\n",
    "    return dataset\n",
    "#     return np.load(os.path.join(TMP_DIR, \"{}.npy\".format(prefix)))\n",
    "    \n",
    "            \n",
    "def loadImagesFromSite(url,prefix):\n",
    "    onlyfiles = [f for f in os.listdir(TMP_DIR) if os.path.isfile(os.path.join(TMP_DIR, f)) and f.startswith(prefix)]\n",
    "    if len(onlyfiles)==0 or FORCE_RELOAD:\n",
    "        imgs = []\n",
    "        I = None\n",
    "        \n",
    "    else:\n",
    "        imgs = [img for img in unpickleBigDataset(prefix)[:HOWMANY]]\n",
    "        I = len(imgs)\n",
    "    print(\"Cached images {}.\".format(I if I is not None else 0))\n",
    "    if len(imgs)<HOWMANY and len(imgs)<MAXLINKS:\n",
    "        print(\"Loading images from {}\".format(url))\n",
    "        print(\"Proceeding from {} image.\".format(I if I is not None else 0))\n",
    "\n",
    "        s = IMAGESPERFILE\n",
    "\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            html = BeautifulSoup(response.read(),\"lxml\")\n",
    "            i = I if I is not None else 0\n",
    "            links = html.find_all('a')[I:HOWMANY]\n",
    "            for link in tqdm_notebook(links):\n",
    "                img = loadImage(link.get('href'))  \n",
    "                img = cv2.resize(img,SIZE)\n",
    "                imgs += [cv2.resize(img,SIZE)]\n",
    "                if i%s==0:\n",
    "                    pickleBigDataset(prefix,imgs,s)\n",
    "                i+=1\n",
    "        pickleBigDataset(prefix,imgs,s)\n",
    "    \n",
    "        \n",
    "    return np.array(imgs)  \n",
    "\n",
    "def saveDataset(X,Y,prefix=\"\"):\n",
    "    with open('pickledDatasetX'+prefix,'wb') as f:\n",
    "        pickle.dump(X,f)\n",
    "    with open('pickledDatasetY'+prefix,'wb') as f:\n",
    "        pickle.dump(Y,f)\n",
    "        \n",
    "def loadDataset(prefix=\"\"):\n",
    "    try:\n",
    "        X = unpickleBigDataset('x')\n",
    "        Y = unpickleBigDataset('y')\n",
    "        if len(X) == len(Y) and len(X) == HOWMANY:\n",
    "            return X,Y\n",
    "        else:\n",
    "            print(\"Failed loading dataset from file system\")\n",
    "            return None,None\n",
    "    except:\n",
    "        print(\"Failed loading dataset from file system\")\n",
    "        return None,None\n",
    "    \n",
    "def display(X,Y,howmany=None):\n",
    "    if howmany is None:\n",
    "        howmany = X.shape[0]\n",
    "        \n",
    "    for i in range(howmany):\n",
    "        print(X[i].max(),X[i].min())\n",
    "        plt.figure()\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(X[i])\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(Y[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_patches(image,size,side,imposition):\n",
    "#     patches = []\n",
    "    \n",
    "    \n",
    "#     for i in range(int(size[0]/side)):\n",
    "#         for j in range(int(size[1]/side)):\n",
    "#             patches += [image[i*side:(i+1)*side,j*side:(j+1)*side]]\n",
    "#     return patches\n",
    "\n",
    "def get_patches(image,size,side,imposition):\n",
    "    patches = []\n",
    "    \n",
    "    if len(image.shape)==3:\n",
    "        img = np.zeros((image.shape[0]+imposition,image.shape[1]+imposition,3))\n",
    "        for i in range(3):\n",
    "            img[...,i] = np.pad(image[...,i],((imposition,0),(imposition,0)),'reflect')\n",
    "        image = img\n",
    "    else:\n",
    "        image = np.pad(image,((imposition,0),(imposition,0)),'reflect')\n",
    "\n",
    "    for i in range(int(size[0]/side)):\n",
    "        for j in range(int(size[1]/side)):\n",
    "            imp1=np.max([i*side-imposition,0])\n",
    "            imp2=(i+1)*side+imposition if imp1!=0 else (i+1)*side+imposition*2\n",
    "            imp3=np.max([j*side-imposition,0])\n",
    "            imp4=(j+1)*side+imposition if imp3!=0 else (j+1)*side+imposition*2\n",
    "            patches += [image[imp1:imp2,imp3:imp4]]\n",
    "    return patches\n",
    "\n",
    "def preprocessorX(image):\n",
    "    size,side,imposition = SIZE,SIDE,IMPOSITION\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    image = image.astype(np.float32)\n",
    "\n",
    "    if image.max() > 1:\n",
    "        image /= 255\n",
    "\n",
    "    for i in range(3):\n",
    "        image[...,i] -= image[...,i].mean()\n",
    "        image[...,i] /= image[...,i].std()\n",
    "\n",
    "    #remove outliers\n",
    "    image[image<-3] = -3\n",
    "    image[image>3] = 3\n",
    "\n",
    "    #between -1,1\n",
    "    for i in range(3):\n",
    "        image[...,i] /= np.max(np.abs([image[...,i].min(),image[...,i].max()]))\n",
    "\n",
    "    return get_patches(image,size,side,imposition)\n",
    "    \n",
    "def preprocessorY(image):\n",
    "    size,side,imposition = SIZE,SIDE,IMPOSITION\n",
    "\n",
    "    image = image.astype(np.float32)\n",
    "    if image.max() > 1:\n",
    "        image /= 255\n",
    "    for i in range(3):\n",
    "        image[...,i] = (image[...,i] - image[...,i].min())/(image[...,i].max() - image[...,i].min())\n",
    "    return get_patches(image,size,side,imposition)\n",
    "    \n",
    "def getRoadStats(arr,mask):\n",
    "    b = mask.astype(np.bool)\n",
    "    x = arr[b]\n",
    "    if len(x) != 0:\n",
    "        return [x.max(0),x.min(0),x.mean(0),x.std(0),np.median(x,axis=0)]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def preprocessXY(X,Y):\n",
    "    \n",
    "    r = []\n",
    "    for i in range(len(X)):\n",
    "        s = getRoadStats(X[i],Y[i])\n",
    "        if s is not None:\n",
    "            r += [s]\n",
    "            \n",
    "    return np.array(r).mean(0)\n",
    "    \n",
    "\n",
    "def preprocess(images,preprocessor,prefix):\n",
    "    onlyfiles = [f for f in os.listdir(TMP_DIR) if os.path.isfile(os.path.join(TMP_DIR, f)) and f.startswith(prefix)]\n",
    "    if len(onlyfiles)==0:\n",
    "        I = None\n",
    "        result = []\n",
    "    else:\n",
    "        result = unpickleBigDataset(prefix)[:HOWMANY*HOWMANYPERIMAGE]\n",
    "        I = len(result)\n",
    "    print(\"Cached images {}.\".format(len(result)))\n",
    "    \n",
    "    s = IMAGESPERFILE * HOWMANYPERIMAGE\n",
    "    if len(result)<HOWMANY*HOWMANYPERIMAGE:\n",
    "        print(\"Preprocessing images.\")\n",
    "        print(\"Proceeding from {} image.\".format(I if I is not None else 0))\n",
    "        i = I if I is not None else 0\n",
    "        ignoring = []\n",
    "        for image in tqdm_notebook(images[I:]):\n",
    "            r = preprocessor(image)\n",
    "            result += r\n",
    "            if i%s==0:\n",
    "                pickleBigDataset(prefix,result,s)\n",
    "        pickleBigDataset(prefix,result,s)\n",
    "    images = None\n",
    "        \n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doSomeDeepLearning(X=None,Y=None,side=85):\n",
    "    num_classes = 2    # ile klas będziemy rozpoznawali\n",
    "\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = side,side   # takie wymiary mają obrazki w bazie MNIST\n",
    "\n",
    "    # the data, shuffled and split between train and test sets\n",
    "    try:\n",
    "        x_train = unpickleBigDataset('xain')\n",
    "        y_train = unpickleBigDataset('yain')\n",
    "        x_test = unpickleBigDataset('xest')\n",
    "        y_test = unpickleBigDataset('yest')\n",
    "        if len(x_train)==0 or len(y_train)==0 or len(x_test)==0 or len(y_test)==0:\n",
    "            raise Exception\n",
    "    except:\n",
    "        if X is None or Y is None:\n",
    "            raise MyException\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "            x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "            y_train = y_train.reshape(y_train.shape[0], 1, img_rows, img_cols)\n",
    "            y_test = y_test.reshape(y_test.shape[0], 1, img_rows, img_cols)\n",
    "            input_shape = (1, img_rows, img_cols)\n",
    "        else:\n",
    "            x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "            x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "            y_train = y_train.reshape(y_train.shape[0], img_rows, img_cols, 1)\n",
    "            y_test = y_test.reshape(y_test.shape[0], img_rows, img_cols, 1)\n",
    "            input_shape = (img_rows, img_cols, 1)\n",
    "        s = IMAGESPERFILE * HOWMANYPERIMAGE\n",
    "        pickleBigDataset('xain',x_train,s)\n",
    "        pickleBigDataset('yain',y_train,s)\n",
    "        pickleBigDataset('xest',x_test,s)\n",
    "        pickleBigDataset('yest',y_test,s)\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    \n",
    "    curr_epoch = -1\n",
    "    onlyfiles = [f for f in os.listdir('.') if os.path.isfile(os.path.join('.', f)) and f.startswith('moj_ulubiony_model') and f.endswith('.h5')]\n",
    "    if len(onlyfiles) == 0:\n",
    "        print(\"No saved model. Preparing model.\")\n",
    "        imput = Input(shape=(side,side,3))\n",
    "        conv1 = Conv2D(32, kernel_size=(3,3),padding=\"same\", activation='relu',kernel_initializer='he_normal')(imput)\n",
    "        conv1 = Conv2D(32, kernel_size=(3,3),padding=\"same\", activation='relu',kernel_initializer='he_normal')(conv1)\n",
    "        conv1 = Conv2D(32, kernel_size=(3,3),padding=\"same\", activation='relu',kernel_initializer='he_normal')(conv1)\n",
    "        dropout1 = Dropout(0.2)(conv1)\n",
    "        maxpool1 = MaxPooling2D(pool_size=(2, 2))(dropout1)\n",
    "        conv2 = Conv2D(64, kernel_size=(3,3),padding=\"same\", activation='relu',kernel_initializer='he_normal')(maxpool1)\n",
    "        conv2 = Conv2D(64, kernel_size=(3,3),padding=\"same\", activation='relu',kernel_initializer='he_normal')(conv2)\n",
    "        conv2 = Conv2D(64, kernel_size=(3,3),padding=\"same\", activation='relu',kernel_initializer='he_normal')(conv2)\n",
    "        dropout2 = Dropout(0.25)(conv2)\n",
    "        maxpool2 = MaxPooling2D(pool_size=(2, 2))(dropout2)\n",
    "        conv3 = Conv2D(128, kernel_size=(3,3),padding=\"same\", activation='relu',kernel_initializer='he_normal')(maxpool2)\n",
    "        conv3 = Conv2D(128, kernel_size=(3,3),padding=\"same\", activation='relu',kernel_initializer='he_normal')(conv3)\n",
    "        conv3 = Conv2D(128, kernel_size=(3,3),padding=\"same\", activation='relu',kernel_initializer='he_normal')(conv3)\n",
    "        dropout3 = Dropout(0.25)(conv3)\n",
    "        upsample1 = UpSampling2D(size=(2,2))(dropout3)\n",
    "        \n",
    "        concat1 = concatenate([upsample1,conv2,])#lambda1])\n",
    "        conv4 = Conv2D(64, kernel_size=(3,3), activation='relu',padding=\"same\",kernel_initializer='he_normal')(concat1)\n",
    "        conv4 = Conv2D(64, kernel_size=(3,3), activation='relu',padding=\"same\",kernel_initializer='he_normal')(conv4)\n",
    "        conv4 = Conv2D(64, kernel_size=(3,3), activation='relu',padding=\"same\",kernel_initializer='he_normal')(conv4)\n",
    "        dropout4 = Dropout(0.25)(conv4)\n",
    "        upsample2 = UpSampling2D(size=(2,2))(dropout4)\n",
    "#         lambda1 = Lambda(lambda image: K.resize_images(image,84/85, 84/85, K.image_data_format()))(conv2)\n",
    "#         crop1 = Cropping2D(((1,0),(1,0)))(conv1)\n",
    "        zpad1 = ZeroPadding2D(((1,0),(1,0)))(upsample2)\n",
    "        concat2 = concatenate([zpad1,conv1])\n",
    "        conv5 = Conv2D(32, kernel_size=(3,3), activation='relu',padding=\"same\",kernel_initializer='he_normal')(concat2)\n",
    "        conv5 = Conv2D(32, kernel_size=(3,3), activation='relu',padding=\"same\",kernel_initializer='he_normal')(conv5)\n",
    "        conv5 = Conv2D(1, kernel_size=(3,3), activation='relu',padding=\"same\",kernel_initializer='he_normal')(conv5)\n",
    "        model = Model(inputs=imput, outputs=conv5)\n",
    "\n",
    "        model.compile(loss=keras.losses.mean_squared_error,\n",
    "                  optimizer=keras.optimizers.Adam(),       \n",
    "                  metrics=['accuracy']) \n",
    "    elif len(onlyfiles) == 1:\n",
    "        print(\"Saved model:\\\"{}\\\"\".format(onlyfiles[0]))\n",
    "        model = keras.models.load_model(onlyfiles[0])\n",
    "    else:\n",
    "        onlyfiles = map(lambda y:filter(lambda x:x is not None and x.startswith('epoch'),y.split('.')[0].split('_')),onlyfiles)\n",
    "        curr_epoch = max(list(map(lambda x:int(x[4:]),onlyfiles)))\n",
    "        model = keras.models.load_model(\"moj_ulubiony_model_epoch{}.h5\".format(curr_epoch))\n",
    "        print(\"Saved model:\\\"moj_ulubiony_model_epoch{}.h5\\\"\".format(curr_epoch))\n",
    "    curr_epoch += 1\n",
    "    print(\"Current epoch:{}\".format(curr_epoch))\n",
    "    model.summary()\n",
    "    for layer in model.layers:\n",
    "        print(layer.get_config())\n",
    "    \n",
    "    \n",
    "    for i in range(curr_epoch,epochs):\n",
    "        model.fit(x_train, y_train,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=1,\n",
    "                      verbose=1,\n",
    "                      validation_data=(x_test, y_test))\n",
    "        model.save(\"moj_ulubiony_model_epoch{}.h5\".format(i))\n",
    "    \n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed loading dataset from file system\n",
      "Loading images (X)\n",
      "Cached images 50.\n",
      "Preprocessing images (X)\n",
      "Cached images 5000.\n",
      "Loading images (Y)\n",
      "Cached images 50.\n",
      "Preprocessing images (Y)\n",
      "Cached images 5000.\n",
      "\n",
      "\t| Hue\t\t\t| Saturation\t\t| Value\n",
      "max\t| 0.7700667221219258\t| 0.3697963440155764\t| 0.5840015321515193\n",
      "min\t| -0.3213364080848538\t| -0.521440711287964\t| -0.3414744058013497\n",
      "avg\t| 0.25378781994227284\t| -0.2957984856996971\t| 0.15707026548488026\n",
      "std\t| 0.2547130276408191\t| 0.1482575176135678\t| 0.1729013025156554\n",
      "median\t| 0.28455884604208853\t| -0.3250359185296453\t| 0.17102898929846352\n",
      "x_train shape: (3500, 85, 85, 3)\n",
      "3500 train samples\n",
      "1500 test samples\n",
      "No saved model. Preparing model.\n",
      "Current epoch:0\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 85, 85, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 85, 85, 32)   896         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 85, 85, 32)   9248        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 85, 85, 32)   9248        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 85, 85, 32)   0           conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 42, 42, 32)   0           dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 42, 42, 64)   18496       max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 42, 42, 64)   36928       conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 42, 42, 64)   36928       conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 42, 42, 64)   0           conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 21, 21, 64)   0           dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 21, 21, 128)  73856       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 21, 21, 128)  147584      conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 21, 21, 128)  147584      conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 21, 21, 128)  0           conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling2D) (None, 42, 42, 128)  0           dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 42, 42, 192)  0           up_sampling2d_11[0][0]           \n",
      "                                                                 conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 42, 42, 64)   110656      concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 42, 42, 64)   36928       conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 42, 42, 64)   36928       conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 42, 42, 64)   0           conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_12 (UpSampling2D) (None, 84, 84, 64)   0           dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 85, 85, 64)   0           up_sampling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 85, 85, 96)   0           zero_padding2d_6[0][0]           \n",
      "                                                                 conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 85, 85, 32)   27680       concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 85, 85, 32)   9248        conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 85, 85, 1)    289         conv2d_86[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 702,497\n",
      "Trainable params: 702,497\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "{'batch_input_shape': (None, 85, 85, 3), 'dtype': 'float32', 'sparse': False, 'name': 'input_6'}\n",
      "{'name': 'conv2d_73', 'trainable': True, 'filters': 32, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'conv2d_74', 'trainable': True, 'filters': 32, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'conv2d_75', 'trainable': True, 'filters': 32, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'dropout_21', 'trainable': True, 'rate': 0.2, 'noise_shape': None, 'seed': None}\n",
      "{'name': 'max_pooling2d_11', 'trainable': True, 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}\n",
      "{'name': 'conv2d_76', 'trainable': True, 'filters': 64, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'conv2d_77', 'trainable': True, 'filters': 64, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'conv2d_78', 'trainable': True, 'filters': 64, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'dropout_22', 'trainable': True, 'rate': 0.25, 'noise_shape': None, 'seed': None}\n",
      "{'name': 'max_pooling2d_12', 'trainable': True, 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}\n",
      "{'name': 'conv2d_79', 'trainable': True, 'filters': 128, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'conv2d_80', 'trainable': True, 'filters': 128, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'conv2d_81', 'trainable': True, 'filters': 128, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'dropout_23', 'trainable': True, 'rate': 0.25, 'noise_shape': None, 'seed': None}\n",
      "{'name': 'up_sampling2d_11', 'trainable': True, 'size': (2, 2), 'data_format': 'channels_last'}\n",
      "{'name': 'concatenate_11', 'trainable': True, 'axis': -1}\n",
      "{'name': 'conv2d_82', 'trainable': True, 'filters': 64, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'conv2d_83', 'trainable': True, 'filters': 64, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'conv2d_84', 'trainable': True, 'filters': 64, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'dropout_24', 'trainable': True, 'rate': 0.25, 'noise_shape': None, 'seed': None}\n",
      "{'name': 'up_sampling2d_12', 'trainable': True, 'size': (2, 2), 'data_format': 'channels_last'}\n",
      "{'name': 'zero_padding2d_6', 'trainable': True, 'padding': ((1, 0), (1, 0)), 'data_format': 'channels_last'}\n",
      "{'name': 'concatenate_12', 'trainable': True, 'axis': -1}\n",
      "{'name': 'conv2d_85', 'trainable': True, 'filters': 32, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'conv2d_86', 'trainable': True, 'filters': 32, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'conv2d_87', 'trainable': True, 'filters': 1, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 2.0, 'mode': 'fan_in', 'distribution': 'normal', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "Train on 3500 samples, validate on 1500 samples\n",
      "Epoch 1/1\n",
      "\r",
      " 128/3500 [>.............................] - ETA: 15:20 - loss: nan - acc: 0.8425\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 256/3500 [=>............................] - ETA: 12:13 - loss: nan - acc: 0.4213\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 384/3500 [==>...........................] - ETA: 10:47 - loss: nan - acc: 0.2808\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 512/3500 [===>..........................] - ETA: 9:56 - loss: nan - acc: 0.2106 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 640/3500 [====>.........................] - ETA: 9:19 - loss: nan - acc: 0.1685\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 768/3500 [=====>........................] - ETA: 9:04 - loss: nan - acc: 0.1404\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 896/3500 [======>.......................] - ETA: 8:31 - loss: nan - acc: 0.1204\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1024/3500 [=======>......................] - ETA: 8:00 - loss: nan - acc: 0.1053\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1152/3500 [========>.....................] - ETA: 7:36 - loss: nan - acc: 0.0936\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1280/3500 [=========>....................] - ETA: 7:11 - loss: nan - acc: 0.0843\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1408/3500 [===========>..................] - ETA: 6:43 - loss: nan - acc: 0.0766\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1536/3500 [============>.................] - ETA: 6:18 - loss: nan - acc: 0.0702\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1664/3500 [=============>................] - ETA: 5:50 - loss: nan - acc: 0.0648\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1792/3500 [==============>...............] - ETA: 5:23 - loss: nan - acc: 0.0602\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1920/3500 [===============>..............] - ETA: 4:59 - loss: nan - acc: 0.0562\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "2048/3500 [================>.............] - ETA: 4:33 - loss: nan - acc: 0.0527\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "2176/3500 [=================>............] - ETA: 4:08 - loss: nan - acc: 0.0496"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-bae652795f81>\u001b[0m in \u001b[0;36mdoSomeDeepLearning\u001b[1;34m(X, Y, side)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMyException\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-5b66e395083f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mdoSomeDeepLearning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mMyException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-bae652795f81>\u001b[0m in \u001b[0;36mdoSomeDeepLearning\u001b[1;34m(X, Y, side)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mY\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMyException\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMyException\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-5b66e395083f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}\\t| {}\\t| {}\\t| {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mdoSomeDeepLearning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-bae652795f81>\u001b[0m in \u001b[0;36mdoSomeDeepLearning\u001b[1;34m(X, Y, side)\u001b[0m\n\u001b[0;32m     98\u001b[0m                       \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                       \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m                       validation_data=(x_test, y_test))\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"moj_ulubiony_model_epoch{}.h5\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jurgad\\Downloads\\WinPython-64bit-3.6.3.0Qt5\\python-3.6.3.amd64\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Users\\jurgad\\Downloads\\WinPython-64bit-3.6.3.0Qt5\\python-3.6.3.amd64\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1236\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1237\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jurgad\\Downloads\\WinPython-64bit-3.6.3.0Qt5\\python-3.6.3.amd64\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jurgad\\Downloads\\WinPython-64bit-3.6.3.0Qt5\\python-3.6.3.amd64\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jurgad\\Downloads\\WinPython-64bit-3.6.3.0Qt5\\python-3.6.3.amd64\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jurgad\\Downloads\\WinPython-64bit-3.6.3.0Qt5\\python-3.6.3.amd64\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jurgad\\Downloads\\WinPython-64bit-3.6.3.0Qt5\\python-3.6.3.amd64\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jurgad\\Downloads\\WinPython-64bit-3.6.3.0Qt5\\python-3.6.3.amd64\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    try:\n",
    "        doSomeDeepLearning()\n",
    "    except MyException as e:\n",
    "        urlX = \"https://www.cs.toronto.edu/~vmnih/data/mass_roads/train/sat/index.html\"\n",
    "        urlY = \"https://www.cs.toronto.edu/~vmnih/data/mass_roads/train/map/index.html\"\n",
    "\n",
    "        X,Y = loadDataset()\n",
    "        if X is None and Y is None or DEBUG:\n",
    "            if LOAD:\n",
    "                print(\"Loading images (X)\")\n",
    "                X = loadImagesFromSite(urlX,'f')\n",
    "            if PREPROCESS:\n",
    "                print(\"Preprocessing images (X)\")\n",
    "                X = preprocess(X,preprocessorX,'x')\n",
    "            if LOAD:\n",
    "                print(\"Loading images (Y)\")\n",
    "                Y = loadImagesFromSite(urlY,'z')\n",
    "            if PREPROCESS:\n",
    "                print(\"Preprocessing images (Y)\")\n",
    "                Y = preprocess(Y,preprocessorY,'y')\n",
    "\n",
    "                r = preprocessXY(X,Y)\n",
    "                print(\"\\n\\t| {}\\t\\t\\t| {}\\t\\t| {}\".format('Hue', 'Saturation', 'Value'))\n",
    "                l = ['max','min','avg','std','median']\n",
    "                for i,(c1, c2, c3) in enumerate(r):  \n",
    "                    print(\"{}\\t| {}\\t| {}\\t| {}\".format(l[i],c1, c2, c3))\n",
    "\n",
    "        doSomeDeepLearning(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
